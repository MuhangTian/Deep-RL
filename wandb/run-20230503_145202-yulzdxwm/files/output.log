[INFO:2023-05-03 14:52:06,194] Episode: 1 | Timesteps Played: 167 | Mean Loss: 0.000 | Mean Reward: 0.599 | Target Updates: 0
[INFO:2023-05-03 14:52:06,482] Episode: 2 | Timesteps Played: 207 | Mean Loss: 0.000 | Mean Reward: 0.773 | Target Updates: 0
[INFO:2023-05-03 14:52:06,771] Episode: 3 | Timesteps Played: 207 | Mean Loss: 0.000 | Mean Reward: 0.773 | Target Updates: 0
Traceback (most recent call last):
  File "/Users/mt361/Desktop/RL-Bandits/train.py", line 63, in <module>
    algo.train()
  File "/Users/mt361/Desktop/RL-Bandits/algo.py", line 450, in train
    action = self.epsilon_greedy(state)
  File "/Users/mt361/Desktop/RL-Bandits/algo.py", line 396, in epsilon_greedy
    return self.Q_network(state.unsqueeze(0)).argmax(1).item()
  File "/usr/local/anaconda3/envs/RL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/mt361/Desktop/RL-Bandits/model.py", line 185, in forward
    X = F.relu(self.conv1(X))
  File "/usr/local/anaconda3/envs/RL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/anaconda3/envs/RL/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/usr/local/anaconda3/envs/RL/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.FloatTensor) and weight type (MPSFloatType) should be the same or input should be a MKLDNN tensor and weight is a dense tensor