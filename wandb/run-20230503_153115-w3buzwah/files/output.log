[INFO:2023-05-03 15:31:18,968] Episode: 1 | Timesteps Played: 167 | Mean Loss: 0.000 | Mean Reward: 0.599 | Target Updates: 0
[INFO:2023-05-03 15:31:19,281] Episode: 2 | Timesteps Played: 207 | Mean Loss: 0.000 | Mean Reward: 0.773 | Target Updates: 0
[INFO:2023-05-03 15:31:27,018] Episode: 3 | Timesteps Played: 207 | Mean Loss: 2.835 | Mean Reward: 0.773 | Target Updates: 0
[INFO:2023-05-03 15:31:37,525] Episode: 4 | Timesteps Played: 129 | Mean Loss: 6.054 | Mean Reward: 0.310 | Target Updates: 0
Traceback (most recent call last):
  File "/Users/mt361/Desktop/RL-Bandits/train.py", line 61, in <module>
    algo.train()
  File "/Users/mt361/Desktop/RL-Bandits/algo.py", line 482, in train
    q_next_values = self.Q_target(replay_next_states).max(dim=1).values.detach()
  File "/usr/local/anaconda3/envs/RL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/mt361/Desktop/RL-Bandits/model.py", line 186, in forward
    X = F.relu(self.conv2(X))
  File "/usr/local/anaconda3/envs/RL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/anaconda3/envs/RL/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/usr/local/anaconda3/envs/RL/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt